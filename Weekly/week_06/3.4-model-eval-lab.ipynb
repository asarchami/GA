{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import cross_val_score, StratifiedKFold, train_test_split, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('../datasets/car.csv')\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     1728\n",
      "unique       4\n",
      "top        med\n",
      "freq       432\n",
      "Name: buying, dtype: object\n",
      "count     1728\n",
      "unique       4\n",
      "top        med\n",
      "freq       432\n",
      "Name: maint, dtype: object\n",
      "count     1728\n",
      "unique       4\n",
      "top          3\n",
      "freq       432\n",
      "Name: doors, dtype: object\n",
      "count     1728\n",
      "unique       3\n",
      "top       more\n",
      "freq       576\n",
      "Name: persons, dtype: object\n",
      "count     1728\n",
      "unique       3\n",
      "top        med\n",
      "freq       576\n",
      "Name: lug_boot, dtype: object\n",
      "count     1728\n",
      "unique       3\n",
      "top        med\n",
      "freq       576\n",
      "Name: safety, dtype: object\n",
      "count      1728\n",
      "unique        4\n",
      "top       unacc\n",
      "freq       1210\n",
      "Name: acceptability, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    print df[column].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['acceptability'])\n",
    "X = pd.get_dummies(df.drop('acceptability', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_things(y, x):\n",
    "    plt.scatter(y, x)\n",
    "    plt.plot([8, 9, 10], [8, 9, 10])\n",
    "    plt.xlim((8,10))\n",
    "    plt.ylim((8,10))\n",
    "    plt.xlabel('Actual Y values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_cv(target):\n",
    "    return StratifiedKFold(target, n_folds=3, shuffle=True, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(model, data, target):\n",
    "    model.fit(data, target)\n",
    "    return model.score(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GridSearchCV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grid_search(model, params, cv):\n",
    "    return GridSearchCV(estimator=model, \n",
    "                    param_grid=params,\n",
    "                    cv=cv\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, data, target, params=None):\n",
    "    x_train, x_test, y_train, y_test=train_test_split(data, target, stratify=target)\n",
    "#     print score(model, x_train, y_train), \"\\n\"\n",
    "    cv=get_cv(y_train)\n",
    "    if params:\n",
    "        grid=grid_search(model, params, cv)\n",
    "    \n",
    "        grid.fit(x_train, y_train)\n",
    "        model = grid.best_estimator_\n",
    "        print \"Best Model after Grid Search:\\n\", model\n",
    "        \n",
    "    else:\n",
    "        model.fit(x_train, y_train)\n",
    "        \n",
    "    s=cross_val_score(model, x_train, y_train, cv=cv, n_jobs=-1)\n",
    "    print \"Mean score of the model is: {}\".format(s.mean())\n",
    "    predictions = model.predict(x_test)\n",
    "    \n",
    "    print \"Confusion Matrix:\\n\",confusion_matrix(y_test, predictions), \"\\n\"\n",
    "    print \"Classification Report:\\n\", classification_report(y_test, predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model after Grid Search:\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=7, p=2,\n",
      "           weights='distance')\n",
      "Mean score of the model is: 0.909753729266\n",
      "Confusion Matrix:\n",
      "[[ 84   2  10   0]\n",
      " [  8   9   0   0]\n",
      " [  6   0 296   0]\n",
      " [  3   2   1  10]] \n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.88      0.85        96\n",
      "          1       0.69      0.53      0.60        17\n",
      "          2       0.96      0.98      0.97       302\n",
      "          3       1.00      0.62      0.77        16\n",
      "\n",
      "avg / total       0.93      0.93      0.92       431\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn=KNeighborsClassifier()\n",
    "params={\n",
    "    'n_neighbors':range(1, len(X.columns)),\n",
    "    'weights':['uniform', 'distance']\n",
    "}\n",
    "knn=evaluate_model(knn, X, y, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score of the model is: 0.893585459642\n",
      "Confusion Matrix:\n",
      "[[ 83   0  13   0]\n",
      " [  8   9   0   0]\n",
      " [  1   0 301   0]\n",
      " [  8   1   0   7]] \n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.86      0.85        96\n",
      "          1       0.90      0.53      0.67        17\n",
      "          2       0.96      1.00      0.98       302\n",
      "          3       1.00      0.44      0.61        16\n",
      "\n",
      "avg / total       0.93      0.93      0.92       431\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=7, p=2,\n",
       "           weights='distance'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bknn=BaggingClassifier(knn)\n",
    "evaluate_model(bknn, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model after Grid Search:\n",
      "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Mean score of the model is: 0.901337190607\n",
      "Confusion Matrix:\n",
      "[[ 78   2  15   1]\n",
      " [ 11   4   0   2]\n",
      " [ 15   0 287   0]\n",
      " [  5   0   0  11]] \n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.81      0.76        96\n",
      "          1       0.67      0.24      0.35        17\n",
      "          2       0.95      0.95      0.95       302\n",
      "          3       0.79      0.69      0.73        16\n",
      "\n",
      "avg / total       0.88      0.88      0.88       431\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = LogisticRegression()\n",
    "params={\n",
    "    'C': [.01, .03, .05, 0.7, .09, .1, .3, .5, .7, 1, 10, 50, 100],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "evaluate_model(log, X, y, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score of the model is: 0.942177323324\n",
      "Confusion Matrix:\n",
      "[[ 93   0   3   0]\n",
      " [  0  17   0   0]\n",
      " [  6   3 293   0]\n",
      " [  0   0   0  16]] \n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.97      0.95        96\n",
      "          1       0.85      1.00      0.92        17\n",
      "          2       0.99      0.97      0.98       302\n",
      "          3       1.00      1.00      1.00        16\n",
      "\n",
      "avg / total       0.97      0.97      0.97       431\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt=DecisionTreeClassifier()\n",
    "evaluate_model(dt, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score of the model is: 0.932135692776\n",
      "Confusion Matrix:\n",
      "[[ 87   0   8   1]\n",
      " [  6  10   0   1]\n",
      " [  2   0 300   0]\n",
      " [  0   0   0  16]] \n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.91      0.91        96\n",
      "          1       1.00      0.59      0.74        17\n",
      "          2       0.97      0.99      0.98       302\n",
      "          3       0.89      1.00      0.94        16\n",
      "\n",
      "avg / total       0.96      0.96      0.96       431\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf=RandomForestClassifier(class_weight='balanced', n_jobs=-1)\n",
    "evaluate_model(rf, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score of the model is: 0.93984647036\n",
      "Confusion Matrix:\n",
      "[[ 91   0   3   2]\n",
      " [  4  12   0   1]\n",
      " [  5   0 297   0]\n",
      " [  0   1   0  15]] \n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.95      0.93        96\n",
      "          1       0.92      0.71      0.80        17\n",
      "          2       0.99      0.98      0.99       302\n",
      "          3       0.83      0.94      0.88        16\n",
      "\n",
      "avg / total       0.96      0.96      0.96       431\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight='balanced',\n",
       "           criterion='gini', max_depth=None, max_features='auto',\n",
       "           max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et = ExtraTreesClassifier(class_weight='balanced', n_jobs=-1)\n",
    "evaluate_model(et, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
