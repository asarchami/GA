{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inorder to get the data from AWS postgres server we can use this command to connect to the server:\n",
    ">psql -h dsi.c20gkj5cvu3l.us-east-1.rds.amazonaws.com -p 5432 -U dsi_student titanic\n",
    "\n",
    "psql will ask for password and after we provide it we can use following command to select everything from database table and export it to csv file:\n",
    ">\\COPY (select * from train) to '~/Downloads/train.csv' DELIMITER ',' csv header;\n",
    "\n",
    "Now that we have our csv file we can move it to an appropriate directory and read it through pandas as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  PassengerId  Survived  Pclass  \\\n",
       "0      0            1         0       3   \n",
       "1      1            2         1       1   \n",
       "2      2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data = pd.read_csv('train.csv')\n",
    "titanic_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ali/anaconda2/lib/python2.7/site-packages/numpy/lib/function_base.py:3834: RuntimeWarning: Invalid value encountered in percentile\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>445.000000</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>222.500000</td>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>445.000000</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>667.500000</td>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>890.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            index  PassengerId    Survived      Pclass         Age  \\\n",
       "count  891.000000   891.000000  891.000000  891.000000  714.000000   \n",
       "mean   445.000000   446.000000    0.383838    2.308642   29.699118   \n",
       "std    257.353842   257.353842    0.486592    0.836071   14.526497   \n",
       "min      0.000000     1.000000    0.000000    1.000000    0.420000   \n",
       "25%    222.500000   223.500000    0.000000    2.000000         NaN   \n",
       "50%    445.000000   446.000000    0.000000    3.000000         NaN   \n",
       "75%    667.500000   668.500000    1.000000    3.000000         NaN   \n",
       "max    890.000000   891.000000    1.000000    3.000000   80.000000   \n",
       "\n",
       "            SibSp       Parch        Fare  \n",
       "count  891.000000  891.000000  891.000000  \n",
       "mean     0.523008    0.381594   32.204208  \n",
       "std      1.102743    0.806057   49.693429  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    7.910400  \n",
       "50%      0.000000    0.000000   14.454200  \n",
       "75%      1.000000    0.000000   31.000000  \n",
       "max      8.000000    6.000000  512.329200  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index          891\n",
       "PassengerId    891\n",
       "Survived       891\n",
       "Pclass         891\n",
       "Name           891\n",
       "Sex            891\n",
       "Age            714\n",
       "SibSp          891\n",
       "Parch          891\n",
       "Ticket         891\n",
       "Fare           891\n",
       "Cabin          204\n",
       "Embarked       889\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = titanic_data.copy() # create a copy of data so original dosn't get modified\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see not all data is available and we have multiple values missing from `Age`, `Cabin` and `Embarked` columns. I think removing data rows will have negative effect on our classification since we dont know how the real data would look like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step would be feature selection. There are some feature that seem to have effect on survival rate based on survival stories. One of them is gender. As our observation first we are going to show survival rate based on gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sex_survive = pd.pivot_table(df, index='Sex', values=['index','Survived'], aggfunc=[np.count_nonzero])\n",
    "sex_survive.columns=['Survived', 'Total']\n",
    "sex_survive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sex_survive.plot(kind='bar', figsize=(10,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see females had better chanse of survival."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also take age to account as a feature. I decided to categorize age so it would be easier to categorize results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Binning:\n",
    "def binning(col, cut_points, labels=None):\n",
    "    #Define min and max values:\n",
    "    minval = col.min()\n",
    "    maxval = col.max()\n",
    "\n",
    "    #create list by adding min and max to cut_points\n",
    "    break_points = [minval] + cut_points + [maxval]\n",
    "\n",
    "    #if no labels provided, use default labels 0 ... (n-1)\n",
    "    if not labels:\n",
    "        labels = range(len(cut_points)+1)\n",
    "\n",
    "    #Binning using cut function of pandas\n",
    "    colBin = pd.cut(col,bins=break_points,labels=labels,include_lowest=True)\n",
    "    return colBin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Binning age:\n",
    "cut_points = [12, 40, 50, 199]\n",
    "labels = ['children', 'young', 'middle_age', 'older', 'no_age']\n",
    "df[\"Age_bin\"] = binning(df[\"Age\"].fillna(200), cut_points, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "age_survive = pd.pivot_table(df, index='Age_bin', values=['index','Survived'], aggfunc=[np.count_nonzero])\n",
    "age_survive.columns=['Survived', 'Total']\n",
    "age_survive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "age_survive.plot(kind='bar', figsize=(10,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see children had better chance of survival."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class also may have effect on survival rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_survive = pd.pivot_table(df, index='Pclass', values=['index','Survived'], aggfunc=[np.count_nonzero])\n",
    "class_survive.columns=['Survived', 'Total']\n",
    "class_survive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_survive.plot(kind='bar', figsize=(10,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see first class passengers had better chance of survival"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Location of the decks could also have effect on survival rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Deck'] = titanic_data.Cabin.fillna('0').apply(lambda x: x[0] if x!='0' else None).to_frame()\n",
    "class_survive = pd.pivot_table(df, index='Deck', values=['index','Survived'], aggfunc=[np.count_nonzero])\n",
    "class_survive.columns=['Survived', 'Total']\n",
    "class_survive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_survive.plot(kind='bar', figsize=(10,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although it seems deck can have a significant survival effect but since there are lots of data missing in `Cabin` column we cannot get a good feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have some clue of features we can use in our prediction I decided to use RFE and Kbest feature selectors to find the best selectors. Therefore I'm just going to dummify and extract feature and through them in feature selectors to find the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decks = pd.get_dummies(df.Deck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.Sex = df.Sex.apply(lambda x: 1 if x=='female' else 0)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "age_bins = pd.get_dummies(df.Age_bin, prefix='Age_bin')\n",
    "age_bins.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pclasses = pd.get_dummies(df.Pclass, prefix='Pclass')\n",
    "pclasses.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embarked = pd.get_dummies(df.Embarked, prefix='Embarked')\n",
    "embarked.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Krew of Titanc were also passenger so we can use it as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "workers = df.Ticket.apply(lambda x: 1 if x=='LINE' else 0).to_frame()\n",
    "workers.columns = ['Worker']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also find out which passenger was sengle or with family and use this information as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "singles = df.apply(lambda x: 1 if (x['SibSp']==0 & x['Parch']==0) else 0, axis=1).to_frame()\n",
    "singles.columns = ['Single']\n",
    "with_family = df.apply(lambda x: 1 if (x['SibSp']==1 or x['Parch']==1) else 0, axis=1).to_frame()\n",
    "with_family.columns = ['WithFamily']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_features(X, feature_list):\n",
    "    for feat in feature_list:\n",
    "        X = X.join(feat, how=\"left\")\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X=df['Sex'].to_frame()\n",
    "y=df['Survived']\n",
    "feature_list = [singles, decks, pclasses, age_bins, with_family, embarked, workers]\n",
    "kbest_selector = SelectKBest(k=5)\n",
    "all_features = combine_features(X, feature_list)\n",
    "feature_count = np.count_nonzero(all_features.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I'm going to use KNN as a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def knn_score(X, y, n=5):\n",
    "    knn = KNeighborsClassifier(n_neighbors=n)\n",
    "    SS = StandardScaler()\n",
    "    knn.fit(SS.fit_transform(X), y)\n",
    "    return knn.score(SS.fit_transform(X), y)\n",
    "\n",
    "def best_knn_k(X,y,max_features, n=5):\n",
    "    max_score = 0\n",
    "    best_k = 0\n",
    "    for i in range(max_features):\n",
    "        kbest = SelectKBest(k=i+1)\n",
    "        score = knn_score(kbest.fit_transform(X, y), y, n=n)\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            best_k = i+1\n",
    "    return best_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "good_features = kbest_selector.fit_transform(all_features, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SS = StandardScaler()\n",
    "knn.fit(SS.fit_transform(good_features), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn.score(SS.fit_transform(good_features), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use kbest selector to select 18 (a random number) good features and compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kbest_selector.k = 18\n",
    "good_features = kbest_selector.fit_transform(all_features, y)\n",
    "knn_score(good_features, y, n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see results change. Now I'll try useing kbest feature selector to find the best number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = best_knn_k(all_features, y, feature_count)\n",
    "kbest_selector.k=k\n",
    "good_features = kbest_selector.fit_transform(all_features, y)\n",
    "print k\n",
    "print knn_score(good_features, y, n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on all our features if we use 11 of our best features we can have the best results with KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm going to use grid search to optimize my models parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier()\n",
    "n_neighbors = [1, 3, 5, 7, 9]\n",
    "weights = ['uniform', 'distance']\n",
    "algorithm=['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "Ps = [1, 2]\n",
    "grid = GridSearchCV(estimator=model, \n",
    "                    param_grid={'n_neighbors': n_neighbors,\n",
    "                                'weights': weights,\n",
    "                                'algorithm':algorithm,\n",
    "                                'p': Ps\n",
    "                               },\n",
    "                    cv = 6\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SS = StandardScaler()\n",
    "grid.fit(SS.fit_transform(good_features),y)\n",
    "best_knn_model = grid.best_estimator_\n",
    "print best_knn_model\n",
    "print grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from above that grid search selected different options for our model which reduces over-fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm going to use cross validation to see if my model produces the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(all_features, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_knn = kbest_selector.fit_transform(x_train, y_train)\n",
    "SS = StandardScaler()\n",
    "best_knn_model.fit(SS.fit_transform(train_knn),y_train)\n",
    "print best_knn_model.score(SS.fit_transform(train_knn),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_knn = kbest_selector.fit_transform(x_test, y_test)\n",
    "SS = StandardScaler()\n",
    "best_knn_model.fit(SS.fit_transform(test_knn),y_test)\n",
    "print best_knn_model.score(SS.fit_transform(test_knn),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see our model was able to categorize the test data with 2% error which is decent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see confusion matrix, Precision/Recall matrix and its heatmap as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# good_features = kbest_selector.fit_transform(all_features, y)\n",
    "SS = StandardScaler()\n",
    "best_knn_model.fit(SS.fit_transform(good_features),y)\n",
    "predictions = best_knn_model.predict(SS.fit_transform(good_features))\n",
    "print \"Confusion matrix: \\n\", confusion_matrix(y, predictions)\n",
    "print \"\\nPrecision Recall:\\n\", classification_report(y, predictions)\n",
    "sns.heatmap(confusion_matrix(y, predictions), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot ROC curve of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = grid.best_estimator_.predict(SS.fit_transform(good_features))\n",
    "FPR = dict()\n",
    "TPR = dict()\n",
    "ROC_AUC = dict()\n",
    "print roc_curve(y, y_pred)\n",
    "FPR[1], TPR[1], _ = roc_curve(y, y_pred)\n",
    "ROC_AUC[1] = auc(FPR[1], TPR[1])\n",
    "plt.figure(figsize=[11,9])\n",
    "plt.plot(FPR[1], TPR[1], label='ROC curve (area = %0.2f)' % ROC_AUC[1], linewidth=4)\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=4)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=18)\n",
    "plt.ylabel('True Positive Rate', fontsize=18)\n",
    "plt.title('ROC for titanic survival with KNN', fontsize=18)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm going to use Logistic Regression as categorizer. This time I'm going to use both Kbest and RFE to find the best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def best_log_rfe_k(X,y,model, max_features, n=5):\n",
    "    max_score = 0\n",
    "    best_k = 0\n",
    "    for i in range(max_features):\n",
    "        rfe = RFE(estimator=model, step=1, n_features_to_select=i+1)\n",
    "        model.fit(rfe.fit_transform(X, y), y)\n",
    "        score = model.score(rfe.fit_transform(X, y), y)\n",
    "        \n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            best_k = i+1\n",
    "    return best_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def best_log_kbest_k(X,y,model,max_features, n=5):\n",
    "    max_score = 0\n",
    "    best_k = 0\n",
    "    for i in range(max_features):\n",
    "        kbest = SelectKBest(k=i+1)\n",
    "        model.fit(kbest.fit_transform(X, y), y)\n",
    "        score = model.score(kbest.fit_transform(X, y), y)\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            best_k = i+1\n",
    "    return best_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "rfe_k = best_log_rfe_k(all_features, y, model, feature_count)\n",
    "print \"best number of features in RFE feature selector: \", rfe_k\n",
    "rfe_log_selector = RFE(estimator=model, step=1, n_features_to_select=rfe_k)\n",
    "best_rfe_features = rfe_log_selector.fit_transform(all_features, y)\n",
    "model.fit(best_rfe_features, y)\n",
    "print model.score(rfe_log_selector.fit_transform(all_features, y), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see `13` is the best number of features and RFE selects them for us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try to improve our selector\n",
    "\n",
    "We can have different parametrs in our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(penalty='l1', C=0.1)\n",
    "print model.fit(best_rfe_features,y)\n",
    "print model.coef_\n",
    "print model.score(best_rfe_features,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(penalty='l1', C=1)\n",
    "print model.fit(best_rfe_features,y)\n",
    "print model.coef_\n",
    "print model.score(best_rfe_features,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(penalty='l2', C=1)\n",
    "print model.fit(best_rfe_features,y)\n",
    "print model.coef_\n",
    "print model.score(best_rfe_features,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "Cs = [.01, .03, .05, 0.7, .09, .1, .3, .5, .7, 1, 10, 50, 100]\n",
    "Ls = ['l1', 'l2']\n",
    "rfe_grid = GridSearchCV(estimator=model, \n",
    "                    param_grid={'C': Cs,\n",
    "                                'penalty': Ls\n",
    "                               },\n",
    "                    cv = 6\n",
    "                   )\n",
    "rfe_grid.fit(best_rfe_features,y)\n",
    "print rfe_grid.best_estimator_\n",
    "print rfe_grid.best_score_\n",
    "log_model_rfe = rfe_grid.best_estimator_\n",
    "predictions = log_model_rfe.predict(best_rfe_features)\n",
    "print \"\\nConfusion Matrix:\\n\", confusion_matrix(y, predictions)\n",
    "print \"\\nPrecision Recall:\\n\", classification_report(y, predictions)\n",
    "sns.heatmap(confusion_matrix(y, predictions), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to cross validate to determine wether our model over-fits or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(all_features, y)\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_rfe = rfe_log_selector.fit_transform(x_train, y_train)\n",
    "print train_rfe.shape\n",
    "train_rfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_model_rfe.fit(train_rfe, y_train)\n",
    "print 'Score with training data (rfe):', log_model_rfe.score(train_rfe, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_rfe = rfe_log_selector.transform(x_test)\n",
    "print 'Score with TEST data (rfe):', log_model_rfe.score(test_rfe, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_model_rfe.fit(x_train, y_train)\n",
    "print 'Score with training data (all):', log_model_rfe.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'With all of our columns! We get:', log_model_rfe.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows our model has low over-fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scores = rfe_log_selector.ranking_\n",
    "\n",
    "predictors = all_features.columns\n",
    "\n",
    "print scores\n",
    "print rfe_log_selector.support_\n",
    "for item in zip(predictors, scores, rfe_log_selector.support_):\n",
    "    print item\n",
    "\n",
    "\n",
    "# # Plot the scores.  See how \"Pclass\", \"Sex\", \"Title\", and \"Fare\" are the best?\n",
    "plt.bar(range(len(predictors)), scores)\n",
    "plt.xticks(range(len(predictors)), predictors, rotation='vertical')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred = log_model_rfe.decision_function(x_test)\n",
    "FPR = dict()\n",
    "TPR = dict()\n",
    "ROC_AUC = dict()\n",
    "print roc_curve(y_test, y_pred)\n",
    "FPR[1], TPR[1], _ = roc_curve(y_test, y_pred)\n",
    "ROC_AUC[1] = auc(FPR[1], TPR[1])\n",
    "plt.figure(figsize=[11,9])\n",
    "plt.plot(FPR[1], TPR[1], label='ROC curve (area = %0.2f)' % ROC_AUC[1], linewidth=4)\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=4)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=18)\n",
    "plt.ylabel('True Positive Rate', fontsize=18)\n",
    "plt.title('ROC for titanic survival with RFE', fontsize=18)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kbest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to do the same for Kbest feature selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def best_log_kbest_k(X,y,model,max_features, n=5):\n",
    "    max_score = 0\n",
    "    best_k = 0\n",
    "    for i in range(max_features):\n",
    "        kbest = SelectKBest(k=i+1)\n",
    "        model.fit(kbest.fit_transform(X, y), y)\n",
    "        score = model.score(kbest.fit_transform(X, y), y)\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            best_k = i+1\n",
    "    return best_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kbest_log_model = LogisticRegression()\n",
    "kbest_k = best_log_kbest_k(all_features, y, kbest_log_model, feature_count)\n",
    "print \"best number of features in Kbest feature selector: \", kbest_k\n",
    "kbest_log_selector = SelectKBest(k=kbest_k)\n",
    "best_kbest_features = kbest_log_selector.fit_transform(all_features, y)\n",
    "kbest_log_model.fit(best_kbest_features, y)\n",
    "print kbest_log_model.score(kbest_log_selector.fit_transform(all_features, y), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Kbest in this model it is better to use `23` features which is all of our features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are using all 23 features results will be the same as all_features and because of that I'm going to use 18 as K so our resuls may vary and compare it to all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kbest_log_selector = SelectKBest(k=18)\n",
    "best_kbest_features = kbest_log_selector.fit_transform(all_features, y)\n",
    "kbest_log_model.fit(best_kbest_features, y)\n",
    "print kbest_log_model.score(kbest_log_selector.fit_transform(all_features, y), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(penalty='l1', C=0.1)\n",
    "print model.fit(best_kbest_features,y)\n",
    "print model.coef_\n",
    "print model.score(best_kbest_features,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(penalty='l1', C=10)\n",
    "print model.fit(best_kbest_features,y)\n",
    "print model.coef_\n",
    "print model.score(best_kbest_features,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So to tweak things further i'm going to use grid search to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "Cs = [.01, .03, .05, 0.7, .09, .1, .3, .5, .7, 1, 10, 50, 100]\n",
    "Ls = ['l1', 'l2']\n",
    "kbes_grid = GridSearchCV(estimator=model, \n",
    "                    param_grid={'C': Cs,\n",
    "                                'penalty': Ls\n",
    "                               },\n",
    "                    cv = 6\n",
    "                   )\n",
    "kbes_grid.fit(best_kbest_features,y)\n",
    "print kbes_grid.best_estimator_\n",
    "print kbes_grid.best_score_\n",
    "log_model_kbest = kbes_grid.best_estimator_\n",
    "predictions = log_model_kbest.predict(best_kbest_features)\n",
    "print \"\\nConfusion Matrix:\\n\", confusion_matrix(y, predictions)\n",
    "print \"\\nPrecision Recall:\\n\", classification_report(y, predictions)\n",
    "sns.heatmap(confusion_matrix(y, predictions), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To crossvalidate again I'm going to split data set to test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(all_features, y)\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_kbest = kbest_log_selector.fit_transform(x_train, y_train)\n",
    "print train_kbest.shape\n",
    "train_kbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_model_kbest.fit(train_kbest, y_train)\n",
    "print 'Score with training data (kbest):', log_model_kbest.score(train_kbest, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_kbest = kbest_log_selector.fit_transform(x_test, y_test)\n",
    "print 'Score with TEST data (kbest):', log_model_kbest.score(test_kbest, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_model_kbest.fit(x_train, y_train)\n",
    "print 'Score with training data (all):', log_model_kbest.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'With all of our columns! We get:', log_model_kbest.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see we have more over-fitting than RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = -np.log10(kbest_log_selector.pvalues_)\n",
    "print scores\n",
    "print kbest_log_selector.pvalues_\n",
    "\n",
    "predictors = all_features.columns\n",
    "\n",
    "# # Plot the scores.  See how \"Pclass\", \"Sex\", \"Title\", and \"Fare\" are the best?\n",
    "plt.bar(range(len(predictors)), scores)\n",
    "plt.xticks(range(len(predictors)), predictors, rotation='vertical')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = log_model_kbest.decision_function(x_test)\n",
    "\n",
    "FPR = dict()\n",
    "TPR = dict()\n",
    "ROC_AUC = dict()\n",
    "\n",
    "print roc_curve(y_test, y_pred)\n",
    "\n",
    "FPR[1], TPR[1], _ = roc_curve(y_test, y_pred)\n",
    "ROC_AUC[1] = auc(FPR[1], TPR[1])\n",
    "\n",
    "\n",
    "plt.figure(figsize=[11,9])\n",
    "plt.plot(FPR[1], TPR[1], label='ROC curve (area = %0.2f)' % ROC_AUC[1], linewidth=4)\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=4)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=18)\n",
    "plt.ylabel('True Positive Rate', fontsize=18)\n",
    "plt.title('Receiver operating characteristic for cancer detection', fontsize=18)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
